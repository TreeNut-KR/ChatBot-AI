'''
íŒŒì¼ì€ FastAPI ì„œë²„ë¥¼ êµ¬ë™í•˜ëŠ” ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ì…ë‹ˆë‹¤.
'''
import os
import yaml
import torch
import uvicorn
import ipaddress

from dotenv import load_dotenv
from asyncio import TimeoutError
from pydantic import ValidationError
from contextlib import asynccontextmanager

from fastapi.staticfiles import StaticFiles
from fastapi.openapi.utils import get_openapi
from fastapi.middleware.cors import CORSMiddleware
from fastapi import (
    APIRouter,
    FastAPI,
    HTTPException,
    Request,
)

from starlette.middleware.base import BaseHTTPMiddleware
from starlette.middleware.sessions import SessionMiddleware

from utils  import (
    ChatError,
    ChatModel,
    ChatSearch,
    LanguageProcessor,
    MongoDBHandler,
    Lumimaid,
    Bllossom,
    OpenAiOffice,
    OpenAiCharacter,
)

load_dotenv()

GREEN="\033[32m"
RED="\033[31m"
YELLOW="\033[33m"
RESET="\033[0m"

Bllossom_model=None                       # Bllossom ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
Lumimaid_model=None                       # Lumimaid ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
# OpenAiOffice_model=None                   # Openai ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
# OpenAiCharacter_model=None                # Openai ìºë¦­í„° ëª¨ë¸ ì „ì—­ ë³€ìˆ˜

languageprocessor=LanguageProcessor() # LanguageProcessor ì´ˆê¸°í™”

try:
    mongo_handler=MongoDBHandler()    # MongoDB í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
except ChatError.InternalServerErrorException as e:
    mongo_handler=None
    print(f"{RED}ERROR{RESET}:    MongoDB ì´ˆê¸°í™” ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
def load_bot_list(file_path: str) -> list:
    """
    YAML íŒŒì¼ì—ì„œ ë´‡ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        file_path (str): ë´‡ ëª©ë¡ì´ ì €ì¥ëœ YAML íŒŒì¼ì˜ ê²½ë¡œ
        
    Returns:
        list: ì†Œë¬¸ìë¡œ ë³€í™˜ëœ ë´‡ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    """
    with open(file_path, 'r', encoding='utf-8') as file:
        data=yaml.safe_load(file)
        return [bot['name'].lower() for bot in data.get('bot_user_agents', [])]

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìˆ˜ëª… ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.
    
    Args:
        app (FastAPI): FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤
        
    Yields:
        None: ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì¢…ë£Œí•  ë•Œê¹Œì§€ ëŒ€ê¸°
    """
    global Bllossom_model, Lumimaid_model, OpenAiOffice_model, OpenAiCharacter_model, GREEN, RESET

    # CUDA ë””ë°”ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
    def get_cuda_device_info(device_id: int) -> str:
        device_name=torch.cuda.get_device_name(device_id)
        device_properties=torch.cuda.get_device_properties(device_id)
        total_memory=device_properties.total_memory / (1024 ** 3)  # GB ë‹¨ìœ„ë¡œ ë³€í™˜
        return f"Device {device_id}: {device_name} (Total Memory: {total_memory:.2f} GB)"
    try:
        # AI ëª¨ë¸ ë¡œë“œ
        Bllossom_model=Bllossom()                 # cuda:1
        Lumimaid_model=Lumimaid()                 # cuda:0
        # OpenAiOffice_model=OpenAiOffice()         # API í˜¸ì¶œ
        # OpenAiCharacter_model=OpenAiCharacter()   # API í˜¸ì¶œ
        
    except ChatError.InternalServerErrorException as e:
        component="LanguageProcessor" if "languageprocessor" not in locals() else "MongoDBHandler"
        print(f"{RED}ERROR{RESET}:    {component} ì´ˆê¸°í™” ì¤‘ {e.__class__.__name__} ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        exit(1)
        
    # ë””ë²„ê¹…ìš© ì¶œë ¥
    Bllossom_device_info=get_cuda_device_info(1)  # Bllossom ëª¨ë¸ì€ cuda:1
    Lumimaid_device_info=get_cuda_device_info(0)  # Lumimaid ëª¨ë¸ì€ cuda:0
    print(f"{GREEN}INFO{RESET}:     Bllossom ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({Bllossom_device_info})")
    print(f"{GREEN}INFO{RESET}:     Lumimaid ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({Lumimaid_device_info})")
    print(f"{GREEN}INFO{RESET}:     OpenAiOffice ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (API í˜¸ì¶œ)")
    print(f"{GREEN}INFO{RESET}:     OpenAiCharacter ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (API í˜¸ì¶œ)")

    yield

    # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
    Bllossom_model=None
    Lumimaid_model=None
    # OpenAiOffice_model=None
    # OpenAiCharacter_model=None
    print(f"{GREEN}INFO{RESET}:     ëª¨ë¸ í•´ì œ ì™„ë£Œ")

app=FastAPI(lifespan=lifespan)  # ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ appì„ ìƒì„±í•©ë‹ˆë‹¤.
ChatError.add_exception_handlers(app)  # ì˜ˆì™¸ í•¸ë“¤ëŸ¬ ì¶”ê°€

class ExceptionMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        """
        HTTP ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´ì…ë‹ˆë‹¤.
        
        Args:
            request (Request): ë“¤ì–´ì˜¤ëŠ” HTTP ìš”ì²­
            call_next (callable): ë‹¤ìŒ ë¯¸ë“¤ì›¨ì–´ë‚˜ ë¼ìš°íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
            
        Returns:
            Response: HTTP ì‘ë‹µ ê°ì²´
        """
        try:
            response=await call_next(request)
            return response
        except Exception as e:
            return await ChatError.generic_exception_handler(request, e)


app.mount(
    "/.well-known/acme-challenge",
    StaticFiles(
        directory=os.path.join(
            os.getcwd(),
            os.getcwd(),
            ".well-known",
            "acme-challenge",
            ),
        ),
    name="acme-challenge",
    )

app.add_middleware(ExceptionMiddleware)
app.add_middleware(
    SessionMiddleware,
    secret_key=os.getenv("SESSION_KEY", "default-secret")
)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def custom_openapi():
    """
    ì»¤ìŠ¤í…€ OpenAPI ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Returns:
        dict: OpenAPI ìŠ¤í‚¤ë§ˆ ì •ì˜
    """
    if app.openapi_schema:
        return app.openapi_schema

    openapi_schema=get_openapi(
        title="ChatBot-AI FastAPI",
        version="v1.5.0",
        routes=app.routes,
        description=(
            "ì´ APIëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:\n\n"
            f"ê° ì—”ë“œí¬ì¸íŠ¸ì˜ ìì„¸í•œ ì •ë³´ëŠ” [ğŸ“Œ ChatBot-AI FastAPI ëª…ì„¸ì„œ](https://github.com/TreeNut-KR/ChatBot-AI/issues/4) ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        ),
    )
    openapi_schema["info"]["x-logo"]={
        "url": "https://drive.google.com/thumbnail?id=12PqUS6bj4eAO_fLDaWQmoq94-771xfim"
    }
    app.openapi_schema=openapi_schema
    return app.openapi_schema

app.openapi=custom_openapi

def is_internal_ip(ip):
    """
    ì£¼ì–´ì§„ IP ì£¼ì†Œê°€ ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ì— ì†í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        ip (str): í™•ì¸í•  IP ì£¼ì†Œ ë¬¸ìì—´
        
    Returns:
        bool: ë‚´ë¶€ IPì¸ ê²½ìš° True, ì•„ë‹Œ ê²½ìš° False
    """
    try:
        ip_obj=ipaddress.ip_address(ip)
        return ip_obj in ipaddress.ip_network(os.getenv("LOCAL_HOST"))
    except ValueError:
        return False

@app.middleware("http")
async def ip_restrict_and_bot_blocking_middleware(request: Request, call_next):
    """
    IP ì œí•œê³¼ ë´‡ ì°¨ë‹¨ì„ ì²˜ë¦¬í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´ì…ë‹ˆë‹¤.
    
    Args:
        request (Request): ë“¤ì–´ì˜¤ëŠ” HTTP ìš”ì²­
        call_next (callable): ë‹¤ìŒ ë¯¸ë“¤ì›¨ì–´ë‚˜ ë¼ìš°íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
        
    Returns:
        Response: HTTP ì‘ë‹µ ê°ì²´
        
    Raises:
        ChatError.IPRestrictedException: í—ˆìš©ë˜ì§€ ì•Šì€ IP ì£¼ì†Œ
        ChatError.BadRequestException: ë´‡ ì ‘ê·¼ ì‹œë„
    """
    ip_string=os.getenv("IP")
    allowed_ips=ip_string.split(", ") if ip_string else []
    client_ip=request.client.host

    bot_user_agents=load_bot_list("./fastapi/src/bot.yaml") # ê²½ë¡œ ìˆ˜ì •
    user_agent=request.headers.get("User-Agent", "").lower()

    try:
        # IP ë° ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ ë²”ìœ„ì— ë”°ë¼ ì•¡ì„¸ìŠ¤ ì œí•œ
        if (request.url.path in ["/office_stream", "/character_stream", "/docs", "/redoc", "/openapi.json"]
                and client_ip not in allowed_ips
                and not is_internal_ip(client_ip)):
            raise ChatError.IPRestrictedException(detail=f"Unauthorized IP address: {client_ip}")

        # ì‚¬ìš©ì ì—ì´ì „íŠ¸ ê¸°ë°˜ ë´‡ ì°¨ë‹¨
        if any(bot in user_agent for bot in bot_user_agents):
            raise ChatError.BadRequestException(detail=f"{user_agent} Bot access is not allowed.")

        response=await call_next(request)
        return response

    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except ChatError.IPRestrictedException as e:
        return await ChatError.generic_exception_handler(request, e)
    except ChatError.BadRequestException as e:
        return await ChatError.generic_exception_handler(request, e)
    except HTTPException as e:
        if (e.status_code == 405):
            raise ChatError.MethodNotAllowedException(detail="The method used is not allowed.")
        raise e
    except Exception as e:
        raise ChatError.InternalServerErrorException(detail="Internal server error occurred.")

@app.get("/")
async def root(request: Request):
    """
    API ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    
    Returns:
        dict: í™˜ì˜ ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ ì‘ë‹µ
    """
    return {
        "message": "Welcome to ChatBot-AI API. Access from IP: " + request.client.host
    }

# ë¼ìš°í„° ì •ì˜
office_router=APIRouter()
character_router=APIRouter()

@office_router.post("/Llama", summary="Llama ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±")
async def office_llama(request: ChatModel.office_Request):
    """
    Bllossom_8B ëª¨ë¸ì— ì§ˆë¬¸ì„ ìœ„í‚¤ë°±ê³¼, ë‚˜ë¬´ìœ„í‚¤, ë‰´ìŠ¤ ë“±ì˜ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ AI ë‹µë³€ì„ JSON ë°©ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        request (ChatModel.office_Request): ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì¸í„°ë„· ê²€ìƒ‰ ì˜µì…˜ í¬í•¨
        
    Returns:
        JSONResponse: JSON ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ì‘ë‹µ
    """
    chat_list=[]
    search_context=""
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler or request.db_id:
        try:
            chat_list=await mongo_handler.get_office_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="office",
            )
        except Exception as e:
            print(f"{YELLOW}WARNING{RESET}:  ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    if request.google_access: # ê²€ìƒ‰ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°
        try:
            duck_results=await ChatSearch.fetch_duck_search_results(query=request.input_data)
        except Exception:
            print(f"{YELLOW}WARNING{RESET}:  ê²€ìƒ‰ì˜ í•œë„ ì´ˆê³¼ë¡œ DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if duck_results:
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results=[]
            for idx, item in enumerate(duck_results[:10], 1):  # ìƒìœ„ 10ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
                formatted_result=(
                    f"[ê²€ìƒ‰ê²°ê³¼ {idx}]\n"
                    f"ì œëª©: {item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                    f"ë‚´ìš©: {item.get('snippet', 'ë‚´ìš© ì—†ìŒ')}\n"
                    f"ì¶œì²˜: {item.get('link', 'ë§í¬ ì—†ìŒ')}\n"
                )
                formatted_results.append(formatted_result)
            
            # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            search_context=(
                "ë‹¤ìŒì€ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n" +
                "\n".join(formatted_results)
            )
    try:        
        # ì¼ë°˜ for ë£¨í”„ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ ëˆ„ì 
        full_response=""
        for chunk in Bllossom_model.generate_response_stream(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        ):
            full_response += chunk
            
        return full_response

    except TimeoutError:
        raise ChatError.InternalServerErrorException(
            detail="Bllossom ëª¨ë¸ ì‘ë‹µì´ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@office_router.post("/gpt4o_mini", summary="gpt4o_mini ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±")
async def office_gpt4o_mini(request: ChatModel.office_Request):
    """
    gpt4o_mini ëª¨ë¸ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ì‘ë‹µì„ JSON ë°©ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        request (ChatModel.office_Request): ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì¸í„°ë„· ê²€ìƒ‰ ì˜µì…˜ í¬í•¨
        
    Returns:
        JSONResponse: JSON ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ì‘ë‹µ
    """
    chat_list=[]
    search_context=""
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler or request.db_id:
        try:
            chat_list=await mongo_handler.get_office_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="office",
            )
        except Exception as e:
            print(f"{YELLOW}WARNING{RESET}:  ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    if request.google_access:  # ê²€ìƒ‰ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°
        try:
            duck_results=await ChatSearch.fetch_duck_search_results(query=request.input_data)
        except Exception:
            print(f"{YELLOW}WARNING{RESET}:  ê²€ìƒ‰ì˜ í•œë„ ì´ˆê³¼ë¡œ DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if duck_results:
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results=[]
            for idx, item in enumerate(duck_results[:10], 1):  # ìƒìœ„ 10ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
                formatted_result=(
                    f"[ê²€ìƒ‰ê²°ê³¼ {idx}]\n"
                    f"ì œëª©: {item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                    f"ë‚´ìš©: {item.get('snippet', 'ë‚´ìš© ì—†ìŒ')}\n"
                    f"ì¶œì²˜: {item.get('link', 'ë§í¬ ì—†ìŒ')}\n"
                )
                formatted_results.append(formatted_result)
            
            # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            search_context=(
                "ë‹¤ìŒì€ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n" +
                "\n".join(formatted_results)
            )

    OpenAiOffice_model=OpenAiOffice(model_id='gpt-4o-mini')  # API í˜¸ì¶œ
    try:
        # ì¼ë°˜ for ë£¨í”„ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ ëˆ„ì 
        full_response=""
        for chunk in OpenAiOffice_model.generate_response_stream(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        ):
            full_response += chunk
            
        return full_response

    except TimeoutError:
        raise ChatError.InternalServerErrorException(
            detail="OpenAI ëª¨ë¸ ì‘ë‹µì´ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@office_router.post("/gpt4.1", summary="gpt4o_mini ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±")
async def office_gpt4o_mini(request: ChatModel.office_Request):
    """
    gpt4o_mini ëª¨ë¸ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ì‘ë‹µì„ JSON ë°©ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        request (ChatModel.office_Request): ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì¸í„°ë„· ê²€ìƒ‰ ì˜µì…˜ í¬í•¨
        
    Returns:
        JSONResponse: JSON ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ì‘ë‹µ
    """
    chat_list=[]
    search_context=""
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler or request.db_id:
        try:
            chat_list=await mongo_handler.get_office_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="office",
            )
        except Exception as e:
            print(f"{YELLOW}WARNING{RESET}:  ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    if request.google_access:  # ê²€ìƒ‰ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°
        try:
            duck_results=await ChatSearch.fetch_duck_search_results(query=request.input_data)
        except Exception:
            print(f"{YELLOW}WARNING{RESET}:  ê²€ìƒ‰ì˜ í•œë„ ì´ˆê³¼ë¡œ DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        if duck_results:
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results=[]
            for idx, item in enumerate(duck_results[:10], 1):  # ìƒìœ„ 10ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
                formatted_result=(
                    f"[ê²€ìƒ‰ê²°ê³¼ {idx}]\n"
                    f"ì œëª©: {item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                    f"ë‚´ìš©: {item.get('snippet', 'ë‚´ìš© ì—†ìŒ')}\n"
                    f"ì¶œì²˜: {item.get('link', 'ë§í¬ ì—†ìŒ')}\n"
                )
                formatted_results.append(formatted_result)
            
            # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            search_context=(
                "ë‹¤ìŒì€ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n" +
                "\n".join(formatted_results)
            )
            
    OpenAiOffice_model=OpenAiOffice(model_id='gpt-4.1')  # API í˜¸ì¶œ
    try:
        # ì¼ë°˜ for ë£¨í”„ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ ëˆ„ì 
        full_response=""
        for chunk in OpenAiOffice_model.generate_response_stream(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        ):
            full_response += chunk
            
        return full_response
    
    except TimeoutError:
        raise ChatError.InternalServerErrorException(
            detail="OpenAI ëª¨ë¸ ì‘ë‹µì´ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@office_router.post("/gpt4.1_mini", summary="gpt4o_mini ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±")
async def office_gpt4o_mini(request: ChatModel.office_Request):
    """
    gpt4o_mini ëª¨ë¸ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ì‘ë‹µì„ JSON ë°©ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        request (ChatModel.office_Request): ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì¸í„°ë„· ê²€ìƒ‰ ì˜µì…˜ í¬í•¨
        
    Returns:
        JSONResponse: JSON ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ì‘ë‹µ
    """
    chat_list=[]
    search_context=""
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler or request.db_id:
        try:
            chat_list=await mongo_handler.get_office_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="office",
            )
        except Exception as e:
            print(f"{YELLOW}WARNING{RESET}:  ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    if request.google_access:  # ê²€ìƒ‰ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°
        try:
            duck_results=await ChatSearch.fetch_duck_search_results(query=request.input_data)
        except Exception:
            print(f"{YELLOW}WARNING{RESET}:  ê²€ìƒ‰ì˜ í•œë„ ì´ˆê³¼ë¡œ DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        if duck_results:
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results=[]
            for idx, item in enumerate(duck_results[:10], 1):  # ìƒìœ„ 10ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©
                formatted_result=(
                    f"[ê²€ìƒ‰ê²°ê³¼ {idx}]\n"
                    f"ì œëª©: {item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                    f"ë‚´ìš©: {item.get('snippet', 'ë‚´ìš© ì—†ìŒ')}\n"
                    f"ì¶œì²˜: {item.get('link', 'ë§í¬ ì—†ìŒ')}\n"
                )
                formatted_results.append(formatted_result)
            
            # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            search_context=(
                "ë‹¤ìŒì€ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n" +
                "\n".join(formatted_results)
            )
            
    OpenAiOffice_model=OpenAiOffice(model_id='gpt-4.1-mini')  # API í˜¸ì¶œ
    try:
        # ì¼ë°˜ for ë£¨í”„ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ ëˆ„ì 
        full_response=""
        for chunk in OpenAiOffice_model.generate_response_stream(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        ):
            full_response += chunk
            
        return full_response
    
    except TimeoutError:
        raise ChatError.InternalServerErrorException(
            detail="OpenAI ëª¨ë¸ ì‘ë‹µì´ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

app.include_router(
    office_router,
    prefix="/office",
    tags=["office Router"],
    responses={500: {"description": "Internal Server Error"}}
)

@character_router.post("/Llama", summary="Llama ëª¨ë¸ì´ ì¼€ë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±")
async def character_llama(request: ChatModel.character_Request):
    """
    Lumimaid_8B ëª¨ë¸ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ìºë¦­í„° ì„¤ì •ì„ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì„ JSON ë°©ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        request (ChatModel.character_Request): ì‚¬ìš©ì ìš”ì²­ ë°ì´í„° í¬í•¨

    Returns:
        JSONResponse: JSON ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ì‘ë‹µ
    """
    chat_list=[]
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler or request.db_id:
        try:
            chat_list=await mongo_handler.get_character_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="character",
            )
        except Exception as e:
            print(f"{YELLOW}WARNING{RESET}:  ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            
    try:
        # ìºë¦­í„° ì„¤ì • êµ¬ì„±
        character_settings={
            "character_name": request.character_name,
            "greeting": request.greeting,
            "context": request.context,
            "chat_list": chat_list,
        }
        # ì¼ë°˜ for ë£¨í”„ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ ëˆ„ì 
        full_response=""
        for chunk in Lumimaid_model.generate_response_stream(
            input_text= request.input_data,
            character_settings=character_settings,
        ):
            full_response += chunk
            
        return full_response

    except TimeoutError:
        raise ChatError.InternalServerErrorException(
            detail="Lumimaid ëª¨ë¸ ì‘ë‹µì´ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@character_router.post("/gpt4o_mini", summary="gpt4o_mini ëª¨ë¸ì´ ì¼€ë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±")
async def character_gpt4o_mini(request: ChatModel.character_Request):
    """
    gpt4o_mini ëª¨ë¸ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ìºë¦­í„° ì„¤ì •ì„ ë°˜ì˜í•˜ì—¬ ë‹µë³€ì„ JSON ë°©ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        request (ChatModel.character_Request): ì‚¬ìš©ì ìš”ì²­ ë°ì´í„° í¬í•¨

    Returns:
        JSONResponse: JSON ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ ì‘ë‹µ
    """
    chat_list=[]
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler or request.db_id:
        try:
            chat_list=await mongo_handler.get_character_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="character",
            )
        except Exception as e:
            print(f"{YELLOW}WARNING{RESET}:  ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            
    OpenAiCharacter_model=OpenAiCharacter(model_id='gpt-4o-mini')  # API í˜¸ì¶œ
    try:
        # ìºë¦­í„° ì„¤ì • êµ¬ì„±
        character_settings={
            "character_name": request.character_name,
            "greeting": request.greeting,
            "context": request.context,
            "chat_list": chat_list,
        }
        # ì¼ë°˜ for ë£¨í”„ë¡œ ë³€ê²½í•˜ì—¬ ì‘ë‹µ ëˆ„ì 
        full_response=""
        for chunk in OpenAiCharacter_model.generate_response_stream(
            input_text= request.input_data,
            character_settings=character_settings,
        ):
            full_response += chunk
            
        return full_response

    except TimeoutError:
        raise ChatError.InternalServerErrorException(
            detail="Lumimaid ëª¨ë¸ ì‘ë‹µì´ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    except ValidationError as e:
        raise ChatError.BadRequestException(detail=str(e))
    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

app.include_router(
    character_router,
    prefix="/character",
    tags=["character Router"],
    responses={500: {"description": "Internal Server Error"}}
)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)

    # logging.basicConfig(level=logging.INFO, format=f"{GREEN}INFO{RESET}:     %(asctime)s - %(levelname)s - %(message)s")
    # logger=logging.getLogger("hypercorn")

    # key_pem=os.getenv("KEY_PEM")
    # crt_pem=os.getenv("CRT_PEM")
    
    # certificates_dir=os.path.abspath(
    #     os.path.join(
    #         os.path.dirname(__file__),
    #         "..",
    #         "certificates",
    #     )
    # )
    # ssl_keyfile=os.path.join(
    #     certificates_dir,
    #     key_pem,
    # )
    # ssl_certfile=os.path.join(
    #     certificates_dir,
    #     crt_pem,
    # )
    
    # if not os.path.isfile(ssl_keyfile) or not os.path.isfile(ssl_certfile):
    #     raise FileNotFoundError("SSL ì¸ì¦ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # config=Config()
    # config.bind=["0.0.0.0:443"]
    # config.certfile=ssl_certfile
    # config.keyfile=ssl_keyfile
    # config.alpn_protocols=["h2", "http/1.1"]  # HTTP/2 í™œì„±í™”
    # config.accesslog="-"  # ìš”ì²­ ë¡œê·¸ í™œì„±í™”

    # async def serve():
    #     logger.info("Starting Hypercorn server...")
    #     await hypercorn.asyncio.serve(app, config)
        
    # asyncio.run(serve())