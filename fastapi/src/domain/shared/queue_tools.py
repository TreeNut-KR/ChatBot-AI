"""
Llama ëª¨ë¸ì˜ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ í†µí•© í í•¸ë“¤ëŸ¬
"""
import asyncio
import time
import uuid
from typing import Dict, Any, Optional, Type
from enum import Enum

from .error_tools import ValueErrorException, InternalServerErrorException

RED = "\033[31m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
BLUE = "\033[34m"
RESET = "\033[0m"

class ServiceType(Enum):
    CHARACTER = "character"
    OFFICE = "office"

class LlamaQueueHandler:
    """
    Llama ëª¨ë¸ì˜ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ê´€ë¦¬í•˜ëŠ” í†µí•© í í•¸ë“¤ëŸ¬
    """
    def __init__(
        self, 
        service_type: ServiceType,
        model_class: Type,
        processing_request_class: Type,
        error_exception_class: Type = InternalServerErrorException,
        max_concurrent: int = 2
    ):
        """
        LlamaQueueHandler ì´ˆê¸°í™” ë©”ì„œë“œ

        Args:
            service_type (ServiceType): ì„œë¹„ìŠ¤ íƒ€ì… (CHARACTER ë˜ëŠ” OFFICE)
            model_class: ì‚¬ìš©í•  ëª¨ë¸ í´ë˜ìŠ¤
            processing_request_class: ì²˜ë¦¬ ìš”ì²­ ë°ì´í„° í´ë˜ìŠ¤
            error_exception_class: ì—ëŸ¬ ì²˜ë¦¬ìš© ì˜ˆì™¸ í´ë˜ìŠ¤ (ê¸°ë³¸ê°’: InternalServerErrorException)
            max_concurrent (int): ë³‘ë ¬ë¡œ ì²˜ë¦¬í•  ì›Œì»¤ì˜ ìˆ˜
        """
        self.service_type = service_type
        self.model_class = model_class
        self.processing_request_class = processing_request_class
        self.error_exception_class = error_exception_class
        self.max_concurrent = max_concurrent
        self.request_queue: asyncio.Queue = asyncio.Queue()
        self.worker_models: list[Optional[Any]] = [None] * self.max_concurrent
        self.is_running = False
        self.total_processed = 0
        self.total_errors = 0
        self.worker_tasks: list[Optional[asyncio.Task]] = [None] * self.max_concurrent

        print(f"{BLUE}INFO{RESET}:     {service_type.value.title()} LlamaQueueHandler ì´ˆê¸°í™” (ë‹¨ì¼ í, {self.max_concurrent} ì›Œì»¤)")

    async def init(self):
        """í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”"""
        try:
            print(f"{GREEN}INFO{RESET}:     {self.service_type.value.title()} LlamaQueueHandler ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"{RED}ERROR{RESET}:    {self.service_type.value.title()} LlamaQueueHandler ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise self.error_exception_class(detail=f"í í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    async def start(self):
        """í ë§¤ë‹ˆì € ì‹œì‘"""
        if not self.is_running:
            self.is_running = True
            # ê° ì›Œì»¤ íƒœìŠ¤í¬ ì‹œì‘
            for i in range(self.max_concurrent):
                self.worker_tasks[i] = asyncio.create_task(self._worker(i))
            print(f"{GREEN}INFO{RESET}:     {self.service_type.value.title()} LlamaQueueHandler ì›Œì»¤ ì‹œì‘ (ë‹¨ì¼ í)")

    async def stop(self):
        """í ë§¤ë‹ˆì € ì •ì§€"""
        self.is_running = False

        # ì›Œì»¤ íƒœìŠ¤í¬ ì •ë¦¬
        for task in self.worker_tasks:
            if task and not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass

        # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
        for i in range(self.max_concurrent):
            self.worker_models[i] = None
        print(f"{YELLOW}INFO{RESET}:     {self.service_type.value.title()} LlamaQueueHandler ì •ì§€ ì™„ë£Œ")

    async def add_character_request(
        self, 
        input_text: str,
        character_settings: Dict[str, Any], 
        user_id: str = "",
        character_name: str = ""
    ) -> str:
        """
        Character ìš”ì²­ì„ íì— ì¶”ê°€í•˜ê³  ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¼
        """
        if self.service_type != ServiceType.CHARACTER:
            raise ValueErrorException(detail="ì´ í•¸ë“¤ëŸ¬ëŠ” Character ì„œë¹„ìŠ¤ìš©ì´ ì•„ë‹™ë‹ˆë‹¤.")
            
        if not self.is_running:
            raise self.error_exception_class(detail="í í•¸ë“¤ëŸ¬ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        request_id = str(uuid.uuid4())
        future = asyncio.Future()
        
        request = self.processing_request_class(
            id=request_id,
            input_text=input_text,
            character_settings=character_settings,
            character_name=character_name,
            future=future,
            created_at=time.time(),
            user_id=user_id
        )
        
        # ë‹¨ì¼ íì— ìš”ì²­ ì¶”ê°€
        await self.request_queue.put(request)
        
        queue_size = self.request_queue.qsize()
        print(
            f"ğŸ”„ ìš”ì²­ ì¶”ê°€: {request_id[:8]} | Character: {character_name} | "
            f"User: {user_id} | Queue: {queue_size}"
        )
        
        # ê²°ê³¼ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        try:
            result = await asyncio.wait_for(future, timeout=300.0)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            return result
        except asyncio.TimeoutError:
            raise self.error_exception_class(detail="ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (5ë¶„)")
        except Exception as e:
            raise self.error_exception_class(detail=f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    async def add_office_request(
        self,
        input_text: str,
        search_text: str,
        chat_list: list, 
        user_id: str = ""
    ) -> str:
        """
        Office ìš”ì²­ì„ íì— ì¶”ê°€í•˜ê³  ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¼
        """
        if self.service_type != ServiceType.OFFICE:
            raise ValueErrorException(detail="ì´ í•¸ë“¤ëŸ¬ëŠ” Office ì„œë¹„ìŠ¤ìš©ì´ ì•„ë‹™ë‹ˆë‹¤.")
            
        if not self.is_running:
            raise self.error_exception_class(detail="í í•¸ë“¤ëŸ¬ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        request_id = str(uuid.uuid4())
        future = asyncio.Future()
        
        request = self.processing_request_class(
            id=request_id,
            input_text=input_text,
            search_text=search_text,
            chat_list=chat_list,
            future=future,
            created_at=time.time(),
            user_id=user_id
        )
        
        # ë‹¨ì¼ íì— ìš”ì²­ ì¶”ê°€
        await self.request_queue.put(request)
        
        queue_size = self.request_queue.qsize()
        print(
            f"ğŸ”„ Office ìš”ì²­ ì¶”ê°€: {request_id[:8]} | "
            f"User: {user_id} | Queue: {queue_size}"
        )
        
        # ê²°ê³¼ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        try:
            result = await asyncio.wait_for(future, timeout=300.0)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            return result
        except asyncio.TimeoutError:
            raise self.error_exception_class(detail="ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (5ë¶„)")
        except Exception as e:
            raise self.error_exception_class(detail=f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    async def _worker(self, worker_id: int):
        """ë³‘ë ¬ ì›Œì»¤ - ê° ì›Œì»¤ê°€ ë‹¨ì¼ íì—ì„œ ìš”ì²­ì„ ê°€ì ¸ì™€ ì²˜ë¦¬"""
        print(f"{BLUE}INFO{RESET}:     {self.service_type.value.title()} Worker-{worker_id} ì‹œì‘ (ë‹¨ì¼ í)")
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ê° ì›Œì»¤ë³„ë¡œ)
        try:
            self.worker_models[worker_id] = self.model_class()
            print(f"{GREEN}INFO{RESET}:     {self.service_type.value.title()} Worker-{worker_id} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"{RED}ERROR{RESET}:    {self.service_type.value.title()} Worker-{worker_id} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return
        
        while self.is_running:
            try:
                # ë‹¨ì¼ íì—ì„œ ìš”ì²­ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                request = await asyncio.wait_for(
                    self.request_queue.get(), 
                    timeout=1.0
                )
                
                actual_start_time = time.time()
                
                # ì„œë¹„ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ë¡œê¹… ë° ì²˜ë¦¬
                if self.service_type == ServiceType.CHARACTER:
                    print(
                        f"ğŸ”„ Worker-{worker_id}: Processing {request.id[:8]} | "
                        f"Character: {request.character_name} | User: {request.user_id}"
                    )
                    
                    # Character ì²˜ë¦¬
                    loop = asyncio.get_event_loop()
                    result = await loop.run_in_executor(
                        None,
                        self.worker_models[worker_id].generate_response,
                        request.input_text,
                        request.character_settings
                    )
                    
                    # Character ì™„ë£Œ ë¡œê¹…
                    actual_processing_time = time.time() - actual_start_time
                    total_time = time.time() - request.created_at
                    
                    print(
                        f"âœ… Worker-{worker_id}: Completed {request.id[:8]} | "
                        f"Character: {request.character_name} | User: {request.user_id} | "
                        f"ProcessTime: {actual_processing_time:.3f}s | "
                        f"TotalTime: {total_time:.3f}s | "
                        f"ResponseLen: {len(result)} chars"
                    )
                    
                else:  # OFFICE
                    print(
                        f"ğŸ”„ Office Worker-{worker_id}: Processing {request.id[:8]} | "
                        f"User: {request.user_id}"
                    )
                    
                    # Office ì²˜ë¦¬
                    loop = asyncio.get_event_loop()
                    result = await loop.run_in_executor(
                        None,
                        self.worker_models[worker_id].generate_response,
                        request.input_text,
                        request.search_text,
                        request.chat_list
                    )
                    
                    # Office ì™„ë£Œ ë¡œê¹…
                    actual_processing_time = time.time() - actual_start_time
                    total_time = time.time() - request.created_at
                    
                    print(
                        f"âœ… Office Worker-{worker_id}: Completed {request.id[:8]} | "
                        f"User: {request.user_id} | "
                        f"ProcessTime: {actual_processing_time:.3f}s | "
                        f"TotalTime: {total_time:.3f}s | "
                        f"ResponseLen: {len(result)} chars"
                    )
                
                # ê²°ê³¼ ê²€ì¦
                if not result or len(result.strip()) < 10:
                    print(f"âš ï¸  Warning: ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: '{result[:50]}...'")
                    result = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ì œëŒ€ë¡œ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                
                # ê²°ê³¼ ì„¤ì •
                if not request.future.cancelled():
                    request.future.set_result(result)
                    self.total_processed += 1
                
            except asyncio.TimeoutError:
                # íƒ€ì„ì•„ì›ƒ - ê³„ì† ëŒ€ê¸°
                continue
            except asyncio.CancelledError:
                # ì •ìƒì ì¸ ì·¨ì†Œ
                break
            except Exception as e:
                self.total_errors += 1
                if 'request' in locals() and not request.future.cancelled():
                    request.future.set_exception(e)
                print(f"âŒ {self.service_type.value.title()} Worker-{worker_id}: Error processing request {request.id[:8]}: {e}")

    def get_queue_status(self) -> Dict[str, Any]:
        """í˜„ì¬ í ìƒíƒœ ë°˜í™˜"""
        return {
            "service_type": self.service_type.value,
            "queue_size": self.request_queue.qsize(),
            "processing_mode": "single_queue",
            "is_running": self.is_running,
            "total_processed": self.total_processed,
            "total_errors": self.total_errors,
            "model_loaded": all(self.worker_models)
        }
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        avg_processing_time = 25.0  # ì˜ˆìƒ í‰ê·  ì²˜ë¦¬ ì‹œê°„
        if self.total_processed > 0:
            avg_processing_time = 25.0  # ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
        
        estimated_wait_time = self.request_queue.qsize() * avg_processing_time / self.max_concurrent
        
        return {
            "service_type": self.service_type.value,
            "total_processed": self.total_processed,
            "total_errors": self.total_errors,
            "success_rate": (
                (self.total_processed / (self.total_processed + self.total_errors)) * 100
                if (self.total_processed + self.total_errors) > 0 else 0
            ),
            "queue_size": self.request_queue.qsize(),
            "estimated_wait_time": f"{estimated_wait_time:.1f}s",
            "avg_processing_time": f"{avg_processing_time:.1f}s",
            "processing_mode": "single_queue",
            "worker_active": any(self.worker_models)
        }