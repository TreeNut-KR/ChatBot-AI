services:
  # 라이브러리 초기화 서비스 (한 번만 실행)
  python-libs-init:
    build:
      context: ./fastapi
      dockerfile: src/Dockerfile.libs
    container_name: python-libs-init
    volumes:
      - python-libs:/opt/python-libs
    command: >
      sh -c "
      if [ ! -f /opt/python-libs/.initialized ]; then
        echo 'Installing Python libraries...'
        pip install --target=/opt/python-libs/lib/python3.11/site-packages 'numpy>=1.22.4,<2.0.0'
        pip install --target=/opt/python-libs/lib/python3.11/site-packages torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 -f https://download.pytorch.org/whl/torch_stable.html
        pip install --target=/opt/python-libs/lib/python3.11/site-packages -r requirements.txt
        CMAKE_ARGS='-DGGML_CUDA=ON' pip install --target=/opt/python-libs/lib/python3.11/site-packages llama-cpp-python --no-cache-dir --force-reinstall
        pip install --target=/opt/python-libs/lib/python3.11/site-packages https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.62+cu121-cp311-cp311-manylinux_2_31_x86_64.whl
        pip install --target=/opt/python-libs/lib/python3.11/site-packages exllamav2 pynvml uvicorn
        touch /opt/python-libs/.initialized
        echo 'Libraries installation completed!'
      else
        echo 'Libraries already installed, skipping...'
      fi
      "

  office:
    build:
      context: ./fastapi
      dockerfile: src/server/office/Dockerfile
    container_name: office
    ports:
      - "8002:8002"
    volumes:
      - python-libs:/opt/python-libs:ro
      # - ./fastapi/ai_model/QuantFactory:/app/fastapi/ai_model/QuantFactory:rw
      - ./fastapi/logs:/app/logs:rw
      - ./fastapi/src/.env:/app/.env:ro
      - ./fastapi/src/bot.yaml:/bot.yaml:ro
    depends_on:
      - python-libs-init
    deploy:
      resources:
        limits:
          memory: 8G      # 메모리 제한 추가
          cpus: '4.0'     # CPU 제한 추가
        # reservations:
        #   memory: 4G      # 최소 메모리 보장
        #   devices:
        #     - driver: nvidia
        #       device_ids: [GPU-4c150f7a-f33e-829b-fed0-21c080a21e96]
        #       capabilities: [gpu]
    environment:
      - TZ=Asia/Seoul
      - NVIDIA_VISIBLE_DEVICES=1
      - CUDA_VISIBLE_DEVICES=1
      - PYTHONPATH=/opt/python-libs/lib/python3.11/site-packages:/app:/app/src
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - MONGO_URL=${MONGO_URL:-mongodb://root:1234@192.168.3.145:27017/chatbot?authSource=admin}
      - UVICORN_HTTP=h11  # HTTP/1.1 강제
      - APP_MODE=office

  character:
    build:
      context: ./fastapi
      dockerfile: src/server/character/Dockerfile
    container_name: character
    ports:
      - "8003:8003"
    volumes:
      - python-libs:/opt/python-libs:ro
      # - ./fastapi/ai_model/QuantFactory:/app/fastapi/ai_model/QuantFactory:rw
      - ./fastapi/logs:/app/logs:rw
      - ./fastapi/src/.env:/app/.env:ro
      - ./fastapi/src/bot.yaml:/bot.yaml:ro

    depends_on:
      - python-libs-init
    deploy:
      resources:
        limits:
          memory: 8G      # 메모리 제한 추가
          cpus: '4.0'     # CPU 제한 추가
        # reservations:
        #   memory: 4G      # 최소 메모리 보장
        #   devices:
        #     - driver: nvidia
        #       device_ids: [GPU-eeda57d0-cf83-ba04-0355-41d7d20ffd54]
        #       capabilities: [gpu]
    environment:
      - TZ=Asia/Seoul
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/opt/python-libs/lib/python3.11/site-packages:/app:/app/src
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - MONGO_URL=${MONGO_URL:-mongodb://root:1234@192.168.3.145:27017/chatbot?authSource=admin}
      - UVICORN_HTTP=h11  # HTTP/1.1 강제
      - APP_MODE=character

  nginx:
    image: nginx:alpine
    container_name: nginx
    ports:
      - "8001:8001"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/404.html:/etc/nginx/html/404.html:ro
    depends_on:
      - office
      - character

volumes:
  python-libs:
    driver: local